{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A hands-on guide to TFRecords\n",
    "\n",
    "The dataset uses TFRecords to store the data. This is a walkthorugh of how to work with TFRecords.\n",
    "\n",
    "The code is based on the following webpage https://towardsdatascience.com/a-practical-guide-to-tfrecords-584536bc786c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf \n",
    "import tqdm\n",
    "import glob"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating 100 random small images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_small_shape = (250,250,3)\n",
    "number_of_images_small = 100\n",
    "\n",
    "images_small = np.random.randint(low=0, high=256, size=(number_of_images_small, *image_small_shape), dtype=np.int16)\n",
    "print(images_small.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating some labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_small = np.random.randint(low=0, high=5, size=(number_of_images_small, 1))\n",
    "labels_small = [label[0] for label in labels_small]\n",
    "print(labels_small[:10])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get these {image, label} pairs into the TFRecord file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bytes_feature(value):\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "    if isinstance(value, type(tf.constant(0))): # if value ist tensor\n",
    "        value = value.numpy() # get value of tensor\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _float_feature(value):\n",
    "  \"\"\"Returns a floast_list from a float / double.\"\"\"\n",
    "  return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "  \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "def serialize_array(array):\n",
    "  array = tf.io.serialize_tensor(array)\n",
    "  return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_single_image(image, label):\n",
    "  \n",
    "  #define the dictionary -- the structure -- of our single example\n",
    "  data = {\n",
    "        'height' : _int64_feature(image.shape[0]),\n",
    "        'width' : _int64_feature(image.shape[1]),\n",
    "        'depth' : _int64_feature(image.shape[2]),\n",
    "        'raw_image' : _bytes_feature(serialize_array(image)),\n",
    "        'label' : _int64_feature(label)\n",
    "    }\n",
    "  #create an Example, wrapping the single features\n",
    "  out = tf.train.Example(features=tf.train.Features(feature=data))\n",
    "\n",
    "  return out"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write our complete dataset to a TFRecord file.write our complete dataset to a TFRecord file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_images_to_tfr_short(images, labels, filename:str=\"images\"):\n",
    "  filename= filename+\".tfrecords\"\n",
    "  writer = tf.io.TFRecordWriter(filename) #create a writer that'll store our data to disk\n",
    "  count = 0\n",
    "\n",
    "  for index in range(len(images)):\n",
    "    #get the data we want to write\n",
    "    current_image = images[index] \n",
    "    current_label = labels[index]\n",
    "\n",
    "    out = parse_single_image(image=current_image, label=current_label)\n",
    "    writer.write(out.SerializeToString())\n",
    "    count += 1\n",
    "\n",
    "  writer.close()\n",
    "  print(f\"Wrote {count} elements to TFRecord\")\n",
    "  return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "count = write_images_to_tfr_short(images_small, labels_small, filename=\"../data/small_images\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the TFRecord file we created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_tfr_element(element):\n",
    "  #use the same structure as above; it's kinda an outline of the structure we now want to create\n",
    "  data = {\n",
    "      'height': tf.io.FixedLenFeature([], tf.int64),\n",
    "      'width':tf.io.FixedLenFeature([], tf.int64),\n",
    "      'label':tf.io.FixedLenFeature([], tf.int64),\n",
    "      'raw_image' : tf.io.FixedLenFeature([], tf.string),\n",
    "      'depth':tf.io.FixedLenFeature([], tf.int64),\n",
    "    }\n",
    "\n",
    "    \n",
    "  content = tf.io.parse_single_example(element, data)\n",
    "  \n",
    "  height = content['height']\n",
    "  width = content['width']\n",
    "  depth = content['depth']\n",
    "  label = content['label']\n",
    "  raw_image = content['raw_image']\n",
    "  \n",
    "  \n",
    "  #get our 'feature'-- our image -- and reshape it appropriately\n",
    "  feature = tf.io.parse_tensor(raw_image, out_type=tf.int16)\n",
    "  feature = tf.reshape(feature, shape=[height,width,depth])\n",
    "  return (feature, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_small(filename):\n",
    "  #create the dataset\n",
    "  dataset = tf.data.TFRecordDataset(filename)\n",
    "\n",
    "  #pass every single feature through our mapping function\n",
    "  dataset = dataset.map(\n",
    "      parse_tfr_element\n",
    "  )\n",
    "    \n",
    "  return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_small = get_dataset_small(\"../data/small_images.tfrecords\")\n",
    "\n",
    "for sample in dataset_small.take(1):\n",
    "  print(sample[0].shape)\n",
    "  print(sample[1].shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Large Dataset and TFRecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_large_shape = (400,750,3)\n",
    "number_of_images_large = 500 #constraining to 500 files here, to not outgrow RAM capacities\n",
    "\n",
    "images_large = np.random.randint(low=0, high=256, size=(number_of_images_large, *image_large_shape), dtype=np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_large = np.random.randint(low=0, high=5, size=(number_of_images_large, 1))\n",
    "labels_large = [label[0] for label in labels_large]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_images_to_tfr_long(images, labels, filename:str=\"large_image\", max_files:int=10, out_dir:str=\"../data/large_dataset/\"):\n",
    "    #determine the number of shards (single TFRecord files) we need:\n",
    "    splits = (len(images)//max_files) + 1 #determine how many tfr shards are needed\n",
    "    if len(images)%max_files == 0:\n",
    "        splits-=1\n",
    "    print(f\"\\nUsing {splits} shard(s) for {len(images)} files, with up to {max_files} samples per shard\")\n",
    "\n",
    "    file_count = 0\n",
    "    for i in tqdm.tqdm(range(splits)):\n",
    "        current_shard_name = f\"{out_dir}{i+1}_{splits}{filename}.tfrecords\"\n",
    "        writer = tf.io.TFRecordWriter(current_shard_name)\n",
    "\n",
    "        current_shard_count = 0\n",
    "        while current_shard_count < max_files: #as long as our shard is not full\n",
    "            #get the index of the file that we want to parse now\n",
    "            index = i*max_files+current_shard_count\n",
    "            if index == len(images): #when we have consumed the whole data, preempt generation\n",
    "                break\n",
    "\n",
    "            current_image = images[index]\n",
    "            current_label = labels[index]\n",
    "\n",
    "            #create the required Example representation\n",
    "            out = parse_single_image(image=current_image, label=current_label)\n",
    "            \n",
    "            writer.write(out.SerializeToString())\n",
    "            current_shard_count+=1\n",
    "            file_count += 1\n",
    "\n",
    "        writer.close()\n",
    "        \n",
    "    print(f\"\\nWrote {file_count} elements to TFRecord\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_images_to_tfr_long(images_large, labels_large, max_files=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_large(tfr_dir:str=\"../data/large_dataset/\", pattern:str=\"*large_image.tfrecords\"):\n",
    "    files = glob.glob(tfr_dir+pattern, recursive=False)\n",
    "\n",
    "    #create the dataset\n",
    "    dataset = tf.data.TFRecordDataset(files)\n",
    "\n",
    "    #pass every single feature through our mapping function\n",
    "    dataset = dataset.map(\n",
    "        parse_tfr_element\n",
    "    )\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_large = get_dataset_large()\n",
    "\n",
    "for sample in dataset_large.take(1):\n",
    "  print(sample[0].shape)\n",
    "  print(sample[1].shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
