{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial on how to use FireDatasetLoader class\n",
    "\n",
    "The tutorial shows you how to load the next day Next Day Wildfire Spread dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fire_dataset_loader import FireDatasetLoader"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install all the required packages\n",
    "\n",
    "You can find the required packages needed to run the class in the requirements.txt file. \n",
    "To install the package on an anaconda environment or vitrual environment run the command below. (uncomment it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Uncomment if you are missing some packages\n",
    "# !pip install -r ../requirements.txt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required Parameters\n",
    "\n",
    "The FireDatasetLoader class requires the data_pattern and index_pattern template strings parameters. The class has other default parameters you can override like data_size, sample_size, and batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pattern = \"/Users/juan/Documents/cpp/masters_project/archive/next_day_wildfire_spread_{}.tfrecord\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Index files\n",
    "\n",
    "Index file must be provided when using multiple workers, otherwise the loader may return duplicate records.\n",
    "\n",
    "You can create the index files with the code below you have to provide a list of TFRecord files and the path where the index files will be stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob \n",
    "import subprocess\n",
    "\n",
    "# TODO: uncomment the for loop and replace the tfrecords_path and index_base_path\n",
    "\n",
    "tfrecords_path = \"/Users/juan/Documents/cpp/masters_project/archive/next_day_wildfire_spread_*\"\n",
    "index_base_path = \"/Users/juan/Documents/cpp/masters_project/archive/index/\"\n",
    "\n",
    "# for file_path in glob.iglob(tfrecords_path):\n",
    "#     file_name = file_path.split(\"/\")[-1].replace(\".tfrecord\", \".index\")\n",
    "#     index_path = index_base_path + file_name\n",
    "#     subprocess.run([\"python3\", \"-m\", \"tfrecord.tools.tfrecord2idx\", file_path, index_path])\n",
    "#     print(f\"Created index file {index_path}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_pattern = \"/Users/juan/Documents/cpp/masters_project/archive/index/next_day_wildfire_spread_{}.index\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating splits dictionaries \n",
    "\n",
    "The splits parameter is a dictionary of (key, value) pairs, where the key is used to\n",
    "construct the data and index path(s) and the value determines\n",
    "the contribution of each split to the batch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_training_files = 15\n",
    "train_splits = {f\"train_{i:02d}\": 1/num_training_files for i in range(num_training_files)}\n",
    "\n",
    "num_test_files = 2\n",
    "test_splits = {f\"test_{i:02d}\": 1/num_test_files for i in range(num_test_files)}\n",
    "\n",
    "num_validation_files = 2\n",
    "eval_splits = {f\"eval_{i:02d}\": 1/num_validation_files for i in range(num_validation_files)}\n",
    "\n",
    "print(train_splits)\n",
    "print(test_splits)\n",
    "print(eval_splits)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating list for input and output features names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_features = [\n",
    "    \"elevation\",\n",
    "    \"th\",\n",
    "    \"vs\",\n",
    "    \"tmmn\",\n",
    "    \"tmmx\",\n",
    "    \"sph\",\n",
    "    \"pr\",\n",
    "    \"pdsi\",\n",
    "    \"NDVI\",\n",
    "    \"population\",\n",
    "    \"erc\",\n",
    "    \"PrevFireMask\",\n",
    "]\n",
    "\n",
    "output_features = [\n",
    "    \"FireMask\",\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the FireDatasetLoader class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = FireDatasetLoader(data_pattern, index_pattern, train_splits, input_features, output_features)\n",
    "training_data_loader = training_data.get_loader()\n",
    "training_features, training_labels = next(iter(training_data_loader))\n",
    "print(training_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data = FireDatasetLoader(data_pattern, index_pattern, test_splits, input_features, output_features, batch_size=50, sample_size=32, center_crop=True)\n",
    "testing_data_loader = testing_data.get_loader()\n",
    "\n",
    "testing_features, testing_labels = next(iter(testing_data_loader))\n",
    "print(testing_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data = FireDatasetLoader(data_pattern, index_pattern, eval_splits, input_features, output_features, batch_size=60)\n",
    "eval_data_loader = eval_data.get_loader()\n",
    "eval_features, eval_labels = next(iter(eval_data_loader))\n",
    "print(eval_features.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "\n",
    "TITLES = [\n",
    "    'Elevation',\n",
    "    'Wind\\ndirection',\n",
    "    'Wind\\nvelocity',\n",
    "    'Min\\ntemp',\n",
    "    'Max\\ntemp',\n",
    "    'Humidity',\n",
    "    'Precip',\n",
    "    'Drought',\n",
    "    'Vegetation',\n",
    "    'Population\\ndensity',\n",
    "    'Energy\\nrelease\\ncomponent',\n",
    "    'Previous\\nfire\\nmask',\n",
    "    'Fire\\nmask'\n",
    "]\n",
    "\n",
    "# TODO: Replace with any other dataset loader \n",
    "inputs = training_features\n",
    "labels = training_labels\n",
    "\n",
    "# Number of rows of data samples to plot\n",
    "n_rows = 5\n",
    "# Number of data variables\n",
    "n_features = inputs.shape[3]\n",
    "# Variables for controllong the color map for the fire masks\n",
    "CMAP = colors.ListedColormap(['black', 'silver', 'orangered'])\n",
    "BOUNDS = [-1, -0.1, 0.001, 1]\n",
    "NORM = colors.BoundaryNorm(BOUNDS, CMAP.N)\n",
    "\n",
    "fig = plt.figure(figsize=(15, 6.5))\n",
    "\n",
    "for i in range(n_rows):\n",
    "    for j in range(n_features + 1):\n",
    "        plt.subplot(n_rows, n_features + 1, i * (n_features + 1) + j + 1)\n",
    "        if i == 0:\n",
    "            plt.title(TITLES[j], fontsize=13)\n",
    "        if j < n_features - 1:\n",
    "            plt.imshow(inputs[i, :, :, j], cmap='viridis')\n",
    "        if j == n_features - 1:\n",
    "            plt.imshow(inputs[i, :, :, -1], cmap=CMAP, norm=NORM)\n",
    "        if j == n_features:\n",
    "            plt.imshow(labels[i, :, :, 0], cmap=CMAP, norm=NORM)\n",
    "        plt.axis('off')\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
